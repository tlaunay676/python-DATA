{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11cba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage du scraping OWID ---\n",
      "Requête vers : https://ourworldindata.org/grapher/burden-of-disease-from-each-category-of-mental-illness.csv\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://ourworldindata.org/grapher/burden-of-disease-from-each-category-of-mental-illness.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 67>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Démarrage du scraping OWID ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# 1. Extraction (Scraping)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Contrairement à l'OMS, on reçoit tout en un seul morceau.\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_owid_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHART_SLUG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDonnées brutes récupérées : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lignes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# 2. Transformation\u001b[39;00m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mget_owid_data\u001b[1;34m(slug)\u001b[0m\n\u001b[0;32m     25\u001b[0m resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Vérification des erreurs HTTP (404, 500, etc.)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Conversion du contenu CSV (texte) en DataFrame pandas.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# On utilise io.StringIO car pd.read_csv attend un fichier ou un buffer, pas une simple string.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(io\u001b[38;5;241m.\u001b[39mStringIO(resp\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\models.py:960\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    957\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code, reason, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://ourworldindata.org/grapher/burden-of-disease-from-each-category-of-mental-illness.csv"
     ]
    }
   ],
   "source": [
    "#scrapping santé mentale\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "# L'URL de base pour les exports CSV des graphiques Our World in Data.\n",
    "# Le \"slug\" correspond à la fin de l'URL de la page du graphique sur leur site.\n",
    "BASE_URL = \"https://ourworldindata.org/grapher/\"\n",
    "CHART_SLUG = \"burden-of-disease-from-each-category-of-mental-illness\"\n",
    "\n",
    "def get_owid_data(slug):\n",
    "    \"\"\"\n",
    "    Récupère le fichier CSV complet associé à un graphique OWID.\n",
    "    --> Correspond à la partie 'Interroger une API / Récupérer la donnée brute'.\n",
    "    \"\"\"\n",
    "    # Construction de l'URL (OWID expose les CSV via /grapher/slug.csv)\n",
    "    url = f\"{BASE_URL}{slug}.csv\"\n",
    "    \n",
    "    print(f\"Requête vers : {url}\")\n",
    "    \n",
    "    # Envoi de la requête HTTP GET\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    # Vérification des erreurs HTTP (404, 500, etc.)\n",
    "    resp.raise_for_status()\n",
    "    \n",
    "    # Conversion du contenu CSV (texte) en DataFrame pandas.\n",
    "    # On utilise io.StringIO car pd.read_csv attend un fichier ou un buffer, pas une simple string.\n",
    "    return pd.read_csv(io.StringIO(resp.content.decode('utf-8')))\n",
    "\n",
    "def process_mental_health_data(df, target_year=2021):\n",
    "    \"\"\"\n",
    "    Nettoie et filtre les données pour ne garder que l'année cible.\n",
    "    --> Correspond à la partie transformation et nettoyage.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Filtrage temporel : on ne veut que l'année 2021\n",
    "    df_filtered = df[df['Year'] == target_year].copy()\n",
    "    \n",
    "    # 2. Nettoyage : On supprime la colonne 'Year' car elle est maintenant constante\n",
    "    # On garde 'Entity' (Pays), 'Code' (Code ISO, utile pour les jointures), et les maladies.\n",
    "    df_filtered = df_filtered.drop(columns=['Year'])\n",
    "    \n",
    "    # 3. Renommage des colonnes pour faciliter l'analyse statistique (éviter les espaces et parenthèses)\n",
    "    # Exemple : \"Depressive disorders (DALYs)\" -> \"Depressive_disorders\"\n",
    "    # Cela rendra l'écriture de tes formules de régression plus simple (ex: smf.ols('Y ~ X'))\n",
    "    df_filtered.columns = [\n",
    "        col.replace(' (DALYs)', '')       # Enlever l'unité\n",
    "           .replace(' ', '_')             # Remplacer espaces par _\n",
    "           .replace('-', '_')             # Remplacer tirets par _\n",
    "        for col in df_filtered.columns\n",
    "    ]\n",
    "    \n",
    "    # 4. Gestion des entités non-pays (OWID inclut des régions comme \"World\", \"Africa\", etc.)\n",
    "    # Si tu ne veux que les pays qui ont un Code ISO (pour exclure les agrégats régionaux) :\n",
    "    df_countries_only = df_filtered.dropna(subset=['Code'])\n",
    "    \n",
    "    return df_countries_only\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PARTIE PRINCIPALE (MAIN)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"--- Démarrage du scraping OWID ---\")\n",
    "\n",
    "    # 1. Extraction (Scraping)\n",
    "    # Contrairement à l'OMS, on reçoit tout en un seul morceau.\n",
    "    raw_df = get_owid_data(CHART_SLUG)\n",
    "    print(f\"Données brutes récupérées : {raw_df.shape[0]} lignes.\")\n",
    "\n",
    "    # 2. Transformation\n",
    "    clean_df = process_mental_health_data(raw_df, target_year=2021)\n",
    "    print(f\"Données filtrées (2021, pays uniquement) : {clean_df.shape[0]} lignes.\")\n",
    "    \n",
    "    # Aperçu des colonnes disponibles pour tes régressions\n",
    "    print(\"\\nColonnes disponibles pour l'analyse :\")\n",
    "    print(clean_df.columns.tolist())\n",
    "\n",
    "    # 3. Chargement (Export CSV)\n",
    "    output_path = \"OWID_Mental_Health_Burden_2021.csv\"\n",
    "    clean_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\nFichier sauvegardé avec succès : {output_path}\")\n",
    "    print(\"Prêt pour l'analyse sur VS Code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff35cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage du scraping OWID (Corrigé) ---\n",
      "Requête vers : https://ourworldindata.org/grapher/burden-disease-from-each-mental-illness.csv\n",
      "\n",
      "Erreur rencontrée : 403 Client Error: Forbidden for url: https://ourworldindata.org/grapher/burden-disease-from-each-mental-illness.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "# CORRECTION ICI : Le bon slug pour ce graphique spécifique\n",
    "BASE_URL = \"https://ourworldindata.org/grapher/\"\n",
    "CHART_SLUG = \"burden-disease-from-each-mental-illness\"\n",
    "\n",
    "def get_owid_data(slug):\n",
    "    \"\"\"\n",
    "    Récupère le fichier CSV complet associé à un graphique OWID.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}{slug}.csv\"\n",
    "    print(f\"Requête vers : {url}\")\n",
    "    \n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status() # Lève une erreur si le lien est mauvais\n",
    "    \n",
    "    return pd.read_csv(io.StringIO(resp.content.decode('utf-8')))\n",
    "\n",
    "def process_mental_health_data(df, target_year=2021):\n",
    "    \"\"\"\n",
    "    Nettoie et filtre les données pour ne garder que l'année cible.\n",
    "    \"\"\"\n",
    "    # 1. Filtrage temporel\n",
    "    df_filtered = df[df['Year'] == target_year].copy()\n",
    "    \n",
    "    # 2. Suppression de la colonne année\n",
    "    df_filtered = df_filtered.drop(columns=['Year'])\n",
    "    \n",
    "    # 3. Renommage des colonnes pour faciliter les régressions (retirer espaces et parenthèses)\n",
    "    # Ex: \"Anxiety disorders (DALYs)\" -> \"Anxiety_disorders\"\n",
    "    df_filtered.columns = [\n",
    "        col.replace(' (DALYs)', '')\n",
    "           .replace(' ', '_')\n",
    "           .replace('-', '_')\n",
    "        for col in df_filtered.columns\n",
    "    ]\n",
    "    \n",
    "    # 4. On ne garde que les lignes qui ont un Code pays (pour éliminer les continents/régions)\n",
    "    df_countries_only = df_filtered.dropna(subset=['Code'])\n",
    "    \n",
    "    return df_countries_only\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PARTIE PRINCIPALE\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"--- Démarrage du scraping OWID (Corrigé) ---\")\n",
    "\n",
    "    try:\n",
    "        # 1. Extraction\n",
    "        raw_df = get_owid_data(CHART_SLUG)\n",
    "        print(f\"Données brutes récupérées : {raw_df.shape[0]} lignes.\")\n",
    "\n",
    "        # 2. Transformation\n",
    "        clean_df = process_mental_health_data(raw_df, target_year=2021)\n",
    "        print(f\"Données filtrées (2021, pays uniquement) : {clean_df.shape[0]} lignes.\")\n",
    "        \n",
    "        # 3. Chargement (Export au bon endroit)\n",
    "        # J'ai mis le chemin absolu pour que ce soit rangé avec tes données OMS\n",
    "        output_path = \"/home/onyxia/python-DATA-1/Données_OMS/OWID_Mental_Health_Burden_2021.csv\"\n",
    "        \n",
    "        clean_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"\\nSUCCÈS ! Fichier sauvegardé ici : {output_path}\")\n",
    "        print(\"Colonnes prêtes pour l'analyse :\", clean_df.columns.tolist())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErreur rencontrée : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77692115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage du scraping OWID (Mode 'User-Agent') ---\n",
      "Requête vers : https://ourworldindata.org/grapher/burden-disease-from-each-mental-illness.csv\n",
      "\n",
      "Une erreur est survenue : 403 Client Error: Forbidden for url: https://ourworldindata.org/grapher/burden-disease-from-each-mental-illness.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "BASE_URL = \"https://ourworldindata.org/grapher/\"\n",
    "CHART_SLUG = \"burden-disease-from-each-mental-illness\"\n",
    "\n",
    "# Chemin de sortie (le même que pour tes données OMS)\n",
    "OUTPUT_PATH = \"/home/onyxia/python-DATA-1/Données_OMS/OWID_Mental_Health_Burden_2021.csv\"\n",
    "\n",
    "def get_owid_data(slug):\n",
    "    \"\"\"\n",
    "    Récupère le fichier CSV en se faisant passer pour un navigateur.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}{slug}.csv\"\n",
    "    print(f\"Requête vers : {url}\")\n",
    "    \n",
    "    # C'EST ICI QUE LA MAGIE OPÈRE :\n",
    "    # On définit un User-Agent pour éviter l'erreur 403.\n",
    "    # Cela fait croire au site qu'on est un utilisateur sur Windows utilisant Chrome.\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    # On ajoute l'argument headers=headers\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Si ça échoue encore, on aura le détail de l'erreur\n",
    "    resp.raise_for_status()\n",
    "    \n",
    "    return pd.read_csv(io.StringIO(resp.content.decode('utf-8')))\n",
    "\n",
    "def process_mental_health_data(df, target_year=2021):\n",
    "    \"\"\"\n",
    "    Nettoie et filtre les données pour ne garder que l'année cible.\n",
    "    \"\"\"\n",
    "    # 1. Filtrage pour 2021\n",
    "    df_filtered = df[df['Year'] == target_year].copy()\n",
    "    \n",
    "    # 2. Suppression de la colonne année inutile\n",
    "    df_filtered = df_filtered.drop(columns=['Year'])\n",
    "    \n",
    "    # 3. Renommage des colonnes (nettoyage des parenthèses et espaces)\n",
    "    df_filtered.columns = [\n",
    "        col.replace(' (DALYs)', '')\n",
    "           .replace(' ', '_')\n",
    "           .replace('-', '_')\n",
    "        for col in df_filtered.columns\n",
    "    ]\n",
    "    \n",
    "    # 4. On garde uniquement les entités qui ont un Code ISO (les pays)\n",
    "    df_countries_only = df_filtered.dropna(subset=['Code'])\n",
    "    \n",
    "    return df_countries_only\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MAIN\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"--- Démarrage du scraping OWID (Mode 'User-Agent') ---\")\n",
    "\n",
    "    try:\n",
    "        # 1. Extraction\n",
    "        raw_df = get_owid_data(CHART_SLUG)\n",
    "        print(f\"Connexion réussie ! Données brutes : {raw_df.shape[0]} lignes.\")\n",
    "\n",
    "        # 2. Transformation\n",
    "        clean_df = process_mental_health_data(raw_df, target_year=2021)\n",
    "        print(f\"Données filtrées (2021, pays uniquement) : {clean_df.shape[0]} lignes.\")\n",
    "        \n",
    "        # 3. Chargement\n",
    "        clean_df.to_csv(OUTPUT_PATH, index=False)\n",
    "        \n",
    "        print(f\"\\nSUCCÈS TOTAL ! Fichier sauvegardé ici :\")\n",
    "        print(OUTPUT_PATH)\n",
    "        print(\"\\nPremières colonnes disponibles :\")\n",
    "        print(clean_df.columns.tolist()[:5]) # Affiche les 5 premières pour vérifier\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nUne erreur est survenue : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9674eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scraping OWID (Mode Avancé) ---\n",
      "Tentative de connexion vers : https://ourworldindata.org/grapher/burden-disease-from-each-mental-illness.csv?v=1\n",
      "\n",
      "❌ ERREUR FATALE : Accès refusé (403). Le site bloque l'IP du serveur Onyxia.\n",
      "--------------------------------------------------\n",
      "SOLUTION DE SECOURS SI L'ERREUR PERSISTE :\n",
      "1. Ouvre ce lien sur ton PC : https://ourworldindata.org/grapher/burden-disease-from-each-mental-illness.csv\n",
      "2. Le fichier va se télécharger.\n",
      "3. Fais un glisser-déposer du fichier dans VS Code vers le dossier : /Données_OMS/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "BASE_URL = \"https://ourworldindata.org/grapher/\"\n",
    "CHART_SLUG = \"burden-disease-from-each-mental-illness\"\n",
    "OUTPUT_PATH = \"/home/onyxia/python-DATA-1/Données_OMS/OWID_Mental_Health_Burden_2021.csv\"\n",
    "\n",
    "def get_owid_data(slug):\n",
    "    \"\"\"\n",
    "    Récupère le CSV en simulant parfaitement une navigation humaine.\n",
    "    \"\"\"\n",
    "    # On ajoute ?v=1 pour simuler le cache browser, parfois ça aide\n",
    "    url = f\"{BASE_URL}{slug}.csv?v=1\" \n",
    "    \n",
    "    print(f\"Tentative de connexion vers : {url}\")\n",
    "    \n",
    "    # HEADERS COMPLETS : On imite Chrome à 100%\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": f\"https://ourworldindata.org/grapher/{slug}\", # Très important : dire qu'on vient de la page du graphique\n",
    "        \"Accept\": \"text/csv,text/plain;q=0.9,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"Connection\": \"keep-alive\"\n",
    "    }\n",
    "    \n",
    "    # On utilise une 'Session' pour gérer les cookies si nécessaire\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    \n",
    "    resp = session.get(url)\n",
    "    \n",
    "    # Gestion d'erreur explicite\n",
    "    if resp.status_code == 403:\n",
    "        raise Exception(\"Accès refusé (403). Le site bloque l'IP du serveur Onyxia.\")\n",
    "    elif resp.status_code == 404:\n",
    "        raise Exception(\"Page non trouvée (404). L'URL est incorrecte.\")\n",
    "        \n",
    "    resp.raise_for_status()\n",
    "    \n",
    "    return pd.read_csv(io.StringIO(resp.content.decode('utf-8')))\n",
    "\n",
    "def process_mental_health_data(df, target_year=2021):\n",
    "    # 1. Filtrage 2021\n",
    "    df_filtered = df[df['Year'] == target_year].copy()\n",
    "    \n",
    "    # 2. Suppression Année\n",
    "    df_filtered = df_filtered.drop(columns=['Year'])\n",
    "    \n",
    "    # 3. Nettoyage colonnes\n",
    "    df_filtered.columns = [\n",
    "        col.replace(' (DALYs)', '').replace(' ', '_').replace('-', '_')\n",
    "        for col in df_filtered.columns\n",
    "    ]\n",
    "    \n",
    "    # 4. Garder les pays seulement\n",
    "    df_countries_only = df_filtered.dropna(subset=['Code'])\n",
    "    \n",
    "    return df_countries_only\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MAIN\n",
    "# ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Scraping OWID (Mode Avancé) ---\")\n",
    "\n",
    "    try:\n",
    "        # 1. Extraction\n",
    "        raw_df = get_owid_data(CHART_SLUG)\n",
    "        print(f\"✅ Données téléchargées : {raw_df.shape[0]} lignes.\")\n",
    "\n",
    "        # 2. Transformation\n",
    "        clean_df = process_mental_health_data(raw_df)\n",
    "        print(f\"✅ Données filtrées : {clean_df.shape[0]} lignes.\")\n",
    "        \n",
    "        # 3. Chargement\n",
    "        clean_df.to_csv(OUTPUT_PATH, index=False)\n",
    "        print(f\"✅ Fichier sauvegardé : {OUTPUT_PATH}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERREUR FATALE : {e}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"SOLUTION DE SECOURS SI L'ERREUR PERSISTE :\")\n",
    "        print(\"1. Ouvre ce lien sur ton PC : https://ourworldindata.org/grapher/burden-disease-from-each-mental-illness.csv\")\n",
    "        print(\"2. Le fichier va se télécharger.\")\n",
    "        print(f\"3. Fais un glisser-déposer du fichier dans VS Code vers le dossier : /Données_OMS/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
